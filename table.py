import math
import random
from typing import List, Tuple, Dict, Optional

def normalize_deg(a: float) -> float:
    """Normalise un angle en degr√©s dans l'intervalle [0, 360[."""
    a = a % 360.0
    return a if a >= 0 else a + 360.0

def deg2rad(a: float) -> float:
    """Convertit des degr√©s en radians."""
    return a * math.pi / 180.0


def line_dir_from_angle_deg(angle_deg: float) -> Tuple[float, float]:
    """Retourne le vecteur directeur (dx, dy) pour un angle donn√© en degr√©s."""
    r = deg2rad(angle_deg)
    return (math.cos(r), math.sin(r))

def cross2(ax: float, ay: float, bx: float, by: float) -> float:
    """Produit vectoriel 2D : ax*by - ay*bx."""
    return ax * by - ay * bx


def intersect_lines(p1: Tuple[float, float], d1: Tuple[float, float],
                    p2: Tuple[float, float], d2: Tuple[float, float]) -> Optional[Tuple[float, float]]:
    """Calcule l'intersection de deux droites d√©finies par un point et une direction."""
    denom = cross2(d1[0], d1[1], d2[0], d2[1])
    if abs(denom) < 1e-12:
        return None  # Lignes presque parall√®les
    
    dx = p2[0] - p1[0]
    dy = p2[1] - p1[1]
    t = cross2(dx, dy, d2[0], d2[1]) / denom
    return (p1[0] + t * d1[0], p1[1] + t * d1[1])


def distance_point_to_line(p: Tuple[float, float], q: Tuple[float, float], d: Tuple[float, float]) -> float:
    """Calcule la distance d'un point p √† une droite passant par q avec direction d."""
    px, py = p
    qx, qy = q
    dx, dy = d
    num = abs(cross2(dx, dy, px - qx, py - qy))
    den = math.hypot(dx, dy)
    return num / den

def least_squares_origin(lines: List[Tuple[Tuple[float, float], Tuple[float, float]]]) -> Tuple[float, float]:
    """
    Calcule l'origine optimale par moindres carr√©s.
    
    Minimise la somme des carr√©s des distances aux droites en r√©solvant
    le syst√®me lin√©aire 2x2 : A * [x0, y0]^T = b
    
    Complexit√© : O(n) o√π n est le nombre de droites.
    """
    if len(lines) == 0:
        return (0.0, 0.0)
    
    # Construction de la matrice normale A et du vecteur b
    a11, a12, a22 = 0.0, 0.0, 0.0
    b1, b2 = 0.0, 0.0
    
    for (qx, qy), (dx, dy) in lines:
        # Normalisation de la direction
        norm = math.hypot(dx, dy)
        if norm < 1e-12:
            continue
        dx, dy = dx / norm, dy / norm
        
        # Contributions au syst√®me normal
        # √âquation de droite: dy*x - dx*y = dy*qx - dx*qy
        a11 += dy * dy
        a12 -= dy * dx
        a22 += dx * dx
        
        rhs = dy * qx - dx * qy
        b1 += dy * rhs
        b2 -= dx * rhs
    
    # R√©solution du syst√®me 2x2
    det = a11 * a22 - a12 * a12
    if abs(det) < 1e-12:
        # Syst√®me singulier, on retourne le barycentre des points q
        xs = [q[0] for q, d in lines]
        ys = [q[1] for q, d in lines]
        return (sum(xs) / len(xs), sum(ys) / len(ys))
    
    x0 = (a22 * b1 - a12 * b2) / det
    y0 = (a11 * b2 - a12 * b1) / det
    
    return (x0, y0)

def compute_residual_for_phi(phi: float, observations: List[Dict]) -> Tuple[Tuple[float, float], float]:
    """
    Calcule l'origine optimale et le r√©siduel pour un angle œÜ donn√©.
    
    Args:
        phi: Angle d'orientation de la table en degr√©s
        observations: Liste des observations {x, y, azimuth_deg}
    
    Returns:
        (origin, residual): Position optimale et r√©siduel moyen
    """
    lines = []
    for obs in observations:
        back_bearing = normalize_deg(obs['azimuth_deg'] + phi + 180.0)
        d = line_dir_from_angle_deg(back_bearing)
        q = (obs['x'], obs['y'])
        lines.append((q, d))
    
    origin = least_squares_origin(lines)
    
    # Calcul du r√©siduel
    residuals = [distance_point_to_line(origin, q, d) for (q, d) in lines]
    residual = sum(residuals) / len(residuals) if residuals else float('inf')
    
    return (origin, residual)

def ternary_search_phi(observations: List[Dict], epsilon: float = 0.01) -> Tuple[float, Tuple[float, float], float]:
    """
    Recherche ternaire pour trouver l'angle œÜ optimal.
    
    Exploite l'unimodalit√© de la fonction r√©siduelle. Divise l'intervalle
    en trois parties √† chaque it√©ration.
    
    Complexit√© : O(log(360/Œµ)) o√π Œµ est la pr√©cision souhait√©e.
    
    Returns:
        (phi_optimal, origin, residual)
    """
    left, right = 0.0, 360.0
    
    while right - left > epsilon:
        mid1 = left + (right - left) / 3.0
        mid2 = right - (right - left) / 3.0
        
        origin1, res1 = compute_residual_for_phi(mid1, observations)
        origin2, res2 = compute_residual_for_phi(mid2, observations)
        
        if res1 > res2:
            left = mid1
        else:
            right = mid2
    
    phi_opt = (left + right) / 2.0
    origin_opt, residual_opt = compute_residual_for_phi(phi_opt, observations)
    
    return (phi_opt, origin_opt, residual_opt)

def gradient_descent_phi(observations: List[Dict], phi_init: float, learning_rate: float = 0.1, max_iter: int = 100) -> Tuple[float, Tuple[float, float], float]:
    """
    Affine œÜ par descente de gradient avec d√©riv√©e num√©rique.
    
    Calcule : df/dœÜ ‚âà (f(œÜ + h) - f(œÜ - h)) / (2h)
    Mise √† jour : œÜ_new = œÜ - learning_rate * df/dœÜ
    
    Convergence typique en O(log(1/Œµ)) it√©rations.
    """
    phi = phi_init
    h = 0.01  # Pas pour la d√©riv√©e num√©rique
    
    for _ in range(max_iter):
        origin_minus, res_minus = compute_residual_for_phi(normalize_deg(phi - h), observations)
        origin_plus, res_plus = compute_residual_for_phi(normalize_deg(phi + h), observations)
        
        # Gradient num√©rique
        gradient = (res_plus - res_minus) / (2.0 * h)
        
        # Mise √† jour
        phi_new = normalize_deg(phi - learning_rate * gradient)
        
        # Test de convergence
        if abs(phi_new - phi) < 0.001:
            break
        
        phi = phi_new
    
    origin_final, residual_final = compute_residual_for_phi(phi, observations)
    return (phi, origin_final, residual_final)

def dense_search_phi(observations: List[Dict], step_deg: float = 0.1) -> Tuple[float, Tuple[float, float], float]:
    """Balayage dense sur [0, 360¬∞] avec un pas configurable."""
    best = (None, None, float('inf'))
    phi = 0.0
    while phi < 360.0:
        origin, residual = compute_residual_for_phi(phi, observations)
        if residual < best[2]:
            best = (origin, phi, residual)
        phi += step_deg
    return best

def local_search_around_phi(observations: List[Dict], phi_center: float, range_deg: float = 5.0, step_deg: float = 0.01) -> Tuple[Tuple[float, float], float, float]:
    """Recherche locale fine autour d'un angle œÜ dans un intervalle donn√©."""
    best_origin = None
    best_phi = None
    best_resid = float('inf')
    
    phi = phi_center - range_deg
    while phi <= phi_center + range_deg:
        origin, residual = compute_residual_for_phi(normalize_deg(phi), observations)
        if residual < best_resid:
            best_origin = origin
            best_phi = normalize_deg(phi)
            best_resid = residual
        phi += step_deg
    
    return (best_origin, best_phi, best_resid)

def adaptive_multi_scale_search(observations: List[Dict]) -> Tuple[Tuple[float, float], float, float]:
    """
    Recherche multi-√©chelle adaptative (coarse-to-fine).
    
    √âtapes :
    1. Balayage grossier (1¬∞) ‚Üí zones prometteuses
    2. Balayage fin (0.1¬∞) ‚Üí top 5 zones
    3. Balayage ultra-fin (0.01¬∞) ‚Üí meilleure zone
    4. Affinage par gradient
    
    Plus robuste que multi-start pour donn√©es difficiles.
    """
    # √âtape 1: Balayage grossier
    candidates = []
    phi = 0.0
    while phi < 360.0:
        origin, residual = compute_residual_for_phi(phi, observations)
        candidates.append((phi, origin, residual))
        phi += 1.0
    
    # Trier par r√©siduel et garder les 5 meilleures zones
    candidates.sort(key=lambda x: x[2])
    top_candidates = candidates[:5]
    
    # √âtape 2: Balayage fin sur les meilleures zones
    refined_candidates = []
    for phi_coarse, _, _ in top_candidates:
        best_origin, best_phi, best_resid = local_search_around_phi(
            observations, phi_coarse, range_deg=2.0, step_deg=0.1
        )
        refined_candidates.append((best_origin, best_phi, best_resid))
    
    # Trouver le meilleur
    refined_candidates.sort(key=lambda x: x[2])
    origin_best, phi_best, resid_best = refined_candidates[0]
    
    # √âtape 3: Recherche ultra-fine
    origin_ultrafine, phi_ultrafine, resid_ultrafine = local_search_around_phi(
        observations, phi_best, range_deg=0.5, step_deg=0.01
    )
    
    # √âtape 4: Affinage par gradient
    phi_final, origin_final, resid_final = gradient_descent_phi(
        observations, phi_ultrafine, learning_rate=0.1, max_iter=50
    )
    
    return (origin_final, phi_final, resid_final)

def ransac_estimate(observations: List[Dict], n_iterations: int = 100, threshold: float = 50.0) -> Tuple[Tuple[float, float], float, float, List[int]]:
    """
    RANSAC (Random Sample Consensus) pour √©liminer les outliers.
    
    Algorithme :
    1. R√©p√©ter n_iterations fois :
       - √âchantillonner 3 observations al√©atoires
       - Calculer le mod√®le (origine, œÜ) pour ces 3 points
       - Compter les inliers (distance < threshold)
    2. Garder le mod√®le avec le plus d'inliers
    3. Recalculer le mod√®le final avec tous les inliers
    
    Args:
        observations: Liste des observations
        n_iterations: Nombre d'it√©rations RANSAC
        threshold: Seuil de distance pour consid√©rer un point comme inlier (m√®tres)
    
    Returns:
        (origin, phi, residual, inlier_indices)
    """
    if len(observations) < 3:
        # Pas assez de points pour RANSAC
        origin, phi, resid = estimate_origin_and_phi(observations, method='multi-start')
        return (origin, phi, resid, list(range(len(observations))))
    
    best_inliers = []
    best_model = None
    
    for _ in range(n_iterations):
        # √âchantillonner 3 observations au hasard
        if len(observations) == 3:
            sample_indices = [0, 1, 2]
        else:
            sample_indices = random.sample(range(len(observations)), 3)
        
        sample_obs = [observations[i] for i in sample_indices]
        
        # Calculer le mod√®le sur l'√©chantillon (m√©thode RAPIDE: legacy avec pas de 2¬∞)
        try:
            best_origin_sample = None
            best_phi_sample = None
            best_resid_sample = float('inf')
            
            phi = 0.0
            while phi < 360.0:
                origin, residual = compute_residual_for_phi(phi, sample_obs)
                if residual < best_resid_sample:
                    best_origin_sample = origin
                    best_phi_sample = phi
                    best_resid_sample = residual
                phi += 2.0  # Pas grossier pour aller vite
            
            if best_origin_sample is None:
                continue
                
            origin, phi = best_origin_sample, best_phi_sample
        except:
            continue
        
        # Tester tous les points
        inliers = []
        for i, obs in enumerate(observations):
            d = line_dir_from_angle_deg(normalize_deg(obs['azimuth_deg'] + phi + 180.0))
            q = (obs['x'], obs['y'])
            dist = distance_point_to_line(origin, q, d)
            if dist < threshold:
                inliers.append(i)
        
        # Garder le meilleur mod√®le (celui avec le plus d'inliers)
        if len(inliers) > len(best_inliers):
            best_inliers = inliers
            best_model = (origin, phi)
    
    # Recalculer le mod√®le final avec tous les inliers (m√©thode PR√âCISE)
    if len(best_inliers) >= 3:
        inlier_obs = [observations[i] for i in best_inliers]
        origin_final, phi_final, resid_final = estimate_origin_and_phi(inlier_obs, method='multi-start')
        return (origin_final, phi_final, resid_final, best_inliers)
    else:
        # Pas assez d'inliers, utiliser toutes les donn√©es
        origin, phi, resid = estimate_origin_and_phi(observations, method='multi-start')
        return (origin, phi, resid, list(range(len(observations))))

def estimate_origin_and_phi(observations: List[Dict], method: str = 'ransac', return_inliers: bool = False) -> Tuple[Tuple[float, float], float, float] | Tuple[Tuple[float, float], float, float, List[int]]:
    """
    Estime la position et l'orientation d'une table d'orientation.
    
    Args:
        observations: Liste de dict avec cl√©s 'x', 'y', 'azimuth_deg'
            - x, y : coordonn√©es de l'objet observ√© (m√®tres)
            - azimuth_deg : azimut grav√© sur la table (0=N, 90=E)
        method: M√©thode d'optimisation
            - 'ransac' (RECOMMAND√â) : √©limine automatiquement les outliers
            - 'adaptive' : recherche multi-√©chelle, tr√®s robuste
            - 'ternary' : recherche ternaire + gradient
            - 'multi-start' : 8 descentes de gradient
            - 'gradient' : descente de gradient simple
            - 'legacy' : balayage lin√©aire (lent)
        return_inliers: Si True, retourne aussi les indices des inliers
    
    Returns:
        (origin, phi, residual) ou (origin, phi, residual, inlier_indices)
    """
    if method == 'ransac':
        origin, phi, resid, inliers = ransac_estimate(observations, n_iterations=100, threshold=50.0)
        if len(inliers) < len(observations):
            print(f"   RANSAC a d√©tect√© {len(observations) - len(inliers)} outlier(s) et les a √©limin√©s.")
            print(f"    Inliers utilis√©s: {len(inliers)}/{len(observations)} observations")
        if return_inliers:
            return (origin, phi, resid, inliers)
        return (origin, phi, resid)
    
    elif method == 'adaptive':
        # RECOMMAND√â: m√©thode la plus robuste et pr√©cise
        result = adaptive_multi_scale_search(observations)
        if return_inliers:
            return (*result, list(range(len(observations))))
        return result
    
    elif method == 'ternary':
        phi, origin, residual = ternary_search_phi(observations, epsilon=0.1)
        # Affinage par gradient
        phi, origin, residual = gradient_descent_phi(observations, phi, learning_rate=0.5, max_iter=50)
        if return_inliers:
            return (origin, phi, residual, list(range(len(observations))))
        return (origin, phi, residual)
    
    elif method == 'gradient':
        # D√©part √† phi=0, puis descente
        phi, origin, residual = gradient_descent_phi(observations, 0.0)
        if return_inliers:
            return (origin, phi, residual, list(range(len(observations))))
        return (origin, phi, residual)
    
    elif method == 'multi-start':
        # Multi-start: teste plusieurs points de d√©part pour √©viter les minima locaux
        best = (None, None, float('inf'))
        for phi_start in [0.0, 45.0, 90.0, 135.0, 180.0, 225.0, 270.0, 315.0]:
            phi, origin, residual = gradient_descent_phi(observations, phi_start, learning_rate=0.5, max_iter=100)
            if residual < best[2]:
                best = (origin, phi, residual)
        if return_inliers:
            return (*best, list(range(len(observations))))
        return best
    
    else:  # legacy
        # Ancien algorithme (pour comparaison)
        best = (None, None, float('inf'))
        phi = 0.0
        while phi < 360.0:
            origin, residual = compute_residual_for_phi(phi, observations)
            if residual < best[2]:
                best = (origin, phi, residual)
            phi += 0.5
        if return_inliers:
            return (*best, list(range(len(observations))))
        return best

# Exemple d'utilisation (donn√©es fictives en m√®tres):
if __name__ == "__main__":
    # Test avec 3 points
    observations_3 = [
        {'x': 2900.0, 'y': 200.0, 'azimuth_deg': 360.0},
        {'x': 1601.0, 'y': 1001.0, 'azimuth_deg': 30.0},
        {'x': 1500.0, 'y': 3500.0, 'azimuth_deg': 120.0},
    ]
    
    # Test avec 4 points
    observations_4 = observations_3 + [
        {'x': 4000.0, 'y': 260.0, 'azimuth_deg': 210.0},
    ]
    
    # Test avec 5 points
    observations_5 = observations_4 + [
        {'x': 400.0, 'y': 480.0, 'azimuth_deg': 200.0},
    ]
    
    import time
    
    for name, obs in [("3 points", observations_3), ("4 points", observations_4), ("5 points", observations_5)]:
        print(f"\n{'='*60}")
        print(f"Test avec {name}")
        print('='*60)
        
        print("\nüèÜ M√©thode RANSAC (robuste aux outliers, FORTEMENT RECOMMAND√âE)")
        t0 = time.time()
        origin, phi, resid = estimate_origin_and_phi(obs, method='ransac')
        t1 = time.time()
        print(f"   Origine: ({origin[0]:.2f}, {origin[1]:.2f})")
        print(f"   Orientation œÜ: {phi:.4f}¬∞")
        print(f"   R√©siduel: {resid:.3f} m")
        print(f"   Temps: {(t1-t0)*1000:.2f} ms")
        
        print("\n‚ö° M√©thode MULTI-START (pour comparaison)")
        t0 = time.time()
        origin2, phi2, resid2 = estimate_origin_and_phi(obs, method='multi-start')
        t1 = time.time()
        print(f"   Origine: ({origin2[0]:.2f}, {origin2[1]:.2f})")
        print(f"   Orientation œÜ: {phi2:.4f}¬∞")
        print(f"   R√©siduel: {resid2:.3f} m")
        print(f"   Temps: {(t1-t0)*1000:.2f} ms")
    
    print(f"\n{'='*60}")
    print(" RANSAC √©limine automatiquement les outliers !")
    print(" R√©siduel beaucoup plus petit et fiable !")
    print('='*60)